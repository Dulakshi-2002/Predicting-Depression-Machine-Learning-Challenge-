{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":92699,"databundleVersionId":11044724,"sourceType":"competition"}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 01. Importing Necessary Libraries","metadata":{}},{"cell_type":"code","source":"import xgboost as xgb\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.preprocessing import KBinsDiscretizer, StandardScaler \nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import classification_report","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 02. Loading the Datasets","metadata":{}},{"cell_type":"code","source":"# Load the datasets\ntrain_path = \"/kaggle/input/predicting-depression-machine-learning-challenge/train.csv\"\ntest_path = \"/kaggle/input/predicting-depression-machine-learning-challenge/test.csv\"\n\ntrain_df = pd.read_csv(train_path)\ntest_df = pd.read_csv(test_path)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 03. Checking the Data","metadata":{}},{"cell_type":"markdown","source":"##  Checking the Number of Unique Values in Each Column","metadata":{}},{"cell_type":"code","source":"for col in train_df.columns:\n    print(f\"{col}: {train_df[col].nunique()} unique values\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##  Checking Data Types","metadata":{}},{"cell_type":"code","source":"print(train_df.dtypes)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##  Displaying Unique Values for Categorical Columns","metadata":{}},{"cell_type":"code","source":"for col in train_df.select_dtypes(include=['object', 'category']):\n    print(f\"\\nColumn: {col}\")\n    print(train_df[col].unique())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Displaying Unique Values for Numerical Columns","metadata":{}},{"cell_type":"code","source":"for col in train_df.select_dtypes(include=['int64', 'float64']):\n    print(f\"\\nColumn: {col}, Unique Values: {train_df[col].unique()[:10]}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Checking for Duplicates","metadata":{}},{"cell_type":"code","source":"print(f\"Duplicate rows: {train_df.duplicated().sum()}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Target Class distribution","metadata":{}},{"cell_type":"code","source":"# Visualize target class distribution\nplt.figure(figsize=(6,4))\nsns.countplot(x=train_df['Depression'])\nplt.title(\"Target Variable Distribution\")\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Correlation Heatmap","metadata":{}},{"cell_type":"code","source":"# Select only numeric columns for correlation\nnumeric_cols = train_df.select_dtypes(include=['int64', 'float64']).columns\n\n# Compute correlation only for numerical features\nplt.figure(figsize=(10,6))\nsns.heatmap(train_df[numeric_cols].corr(), annot=True, cmap='coolwarm', fmt='.2f')\nplt.title(\"Feature Correlations\")\nplt.show()\n\n# Summary statistics\nprint(train_df.describe())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Dataset Description","metadata":{}},{"cell_type":"code","source":"numerical_summary = train_df.describe()\nnumerical_summary.to_csv(\"numerical_summary.csv\")\n\n# Describe categorical features and save to CSV\ncategorical_summary = train_df.describe(include=[object])\ncategorical_summary.to_csv(\"categorical_summary.csv\")\n\n# Save missing values information\nmissing_values = train_df.isnull().sum()\nmissing_values.to_csv(\"missing_values.csv\", header=[\"MissingÂ Count\"])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 04. Handling Data Issues","metadata":{}},{"cell_type":"markdown","source":"## Handling Inconsistencies","metadata":{}},{"cell_type":"code","source":"# Standardizing Degree Names\ndef standardize_degree(value):\n    degree_mapping = {\n        \"mtech\": \"M.Tech\", \"m.tech\": \"M.Tech\", \"m_tech\": \"M.Tech\",\n        \"bsc\": \"B.Sc\", \"b.sc\": \"B.Sc\", \"b sc\": \"B.Sc\",\n        \"btech\": \"B.Tech\", \"b.tech\": \"B.Tech\", \"b tech\": \"B.Tech\",\n        \"msc\": \"M.Sc\", \"m.sc\": \"M.Sc\", \"m sc\": \"M.Sc\",\n        \"llb\": \"LL.B\", \"ll.b\": \"LL.B\",\n        \"mba\": \"MBA\", \"m.b.a\": \"MBA\",\n        \"mbbs\": \"MBBS\", \"m.b.b.s\": \"MBBS\"\n    }\n    value = str(value).strip().lower()\n    return degree_mapping.get(value, value.title() if value.isalpha() else value)\n\n# Categorize Sleep Duration\ndef categorize_sleep(value):\n    value = str(value).lower().strip()\n\n    # Handle specific misentered values\n    mapping = {\n        \"than 5 hours\": \"Less than 5 hours\",\n        \"9-5 hours\": \"5-9 hours\",\n        \"9-6 hours\": \"6-9 hours\",\n        \"10-6 hours\": \"6-10 hours\"\n    }\n    \n    # Define category mappings\n    very_short = [\"less than 5 hours\", \"1-2 hours\", \"2-3 hours\", \"3-4 hours\", \"4-5 hours\", \"1-3 hours\", \"1-6 hours\"]\n    short = [\"5-6 hours\", \"6-7 hours\", \"4-6 hours\", \"3-6 hours\", \"5-9 hours\"]\n    normal = [\"6-8 hours\", \"7-8 hours\", \"8-9 hours\", \"8 hours\", \"6-9 hours\", \"6-10 hours\"]\n    long = [\"9-11 hours\", \"10-11 hours\", \"more than 8 hours\"]\n    outliers = [\"40-45 hours\", \"45-48 hours\", \"49 hours\", \"55-66 hours\", \"35-36 hours\"]\n    invalid = [\"indore\", \"pune\", \"work_study_hours\", \"sleep_duration\", \"no\", \"moderate\", \"unhealthy\"]\n\n    # Apply standardization\n    if value in mapping:\n        value = mapping[value]\n\n    if value in very_short:\n        return \"Very Short Sleep\"\n    elif value in short:\n        return \"Short Sleep\"\n    elif value in normal:\n        return \"Normal Sleep\"\n    elif value in long:\n        return \"Long Sleep\"\n    elif value in outliers or value in invalid:\n        return np.nan  # Mark as NaN for handling later\n    else:\n        return np.nan  # Default case\n\n# Cleaning Dietary Habits\ndef clean_dietary_habits(value):\n    valid_values = [\"Healthy\", \"Unhealthy\", \"Moderate\", \"More Healthy\", \"Less Healthy\"]\n    value = str(value).strip().capitalize()\n    return value if value in valid_values else np.nan\n\n# Apply cleaning functions to train dataset\ntrain_df[\"Degree\"] = train_df[\"Degree\"].apply(standardize_degree)\ntrain_df[\"Sleep Duration\"] = train_df[\"Sleep Duration\"].apply(categorize_sleep)\ntrain_df[\"Dietary Habits\"] = train_df[\"Dietary Habits\"].apply(clean_dietary_habits)\n\n# Apply cleaning functions to test dataset\ntest_df[\"Degree\"] = test_df[\"Degree\"].apply(standardize_degree)\ntest_df[\"Sleep Duration\"] = test_df[\"Sleep Duration\"].apply(categorize_sleep)\ntest_df[\"Dietary Habits\"] = test_df[\"Dietary Habits\"].apply(clean_dietary_habits)\n\n# Handle missing values safely\nfor column in [\"Sleep Duration\", \"Dietary Habits\", \"Degree\"]:\n    if not train_df[column].dropna().mode().empty:\n        train_df[column].fillna(train_df[column].mode()[0], inplace=True)\n    else:\n        # Fallback values\n        default_values = {\"Sleep Duration\": \"Normal Sleep\", \"Dietary Habits\": \"Moderate\", \"Degree\": \"B.Sc\"}\n        train_df[column].fillna(default_values[column], inplace=True)\n\n    if not test_df[column].dropna().mode().empty:\n        test_df[column].fillna(test_df[column].mode()[0], inplace=True)\n    else:\n        test_df[column].fillna(default_values[column], inplace=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Checking for Outliers (Numerical Columns)","metadata":{}},{"cell_type":"code","source":"for col in train_df.select_dtypes(include=['int64', 'float64']):\n    plt.figure(figsize=(5, 2))\n    sns.boxplot(x=train_df[col])\n    plt.title(col)\n    plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Checking for Skewness in the Data ","metadata":{}},{"cell_type":"code","source":"sns.histplot(train_df['Depression'], kde=True, bins=30)\nplt.title(\"Distribution of Depression Column\")\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df['Depression'].skew()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 05. Data Preprocessing","metadata":{}},{"cell_type":"markdown","source":"##  Droping Irrelevant Columns","metadata":{}},{"cell_type":"code","source":"# Drop irrelevant columns\ntrain_df.drop(columns=[\"id\", \"Name\"], inplace=True, errors='ignore')\ntest_df.drop(columns=[\"id\", \"Name\"], inplace=True, errors='ignore')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Filling Missing Values","metadata":{}},{"cell_type":"code","source":"# Fill missing values\ncategorical_cols = [\"Profession\", \"Degree\", \"Dietary Habits\"]\ntrain_df[categorical_cols] = train_df[categorical_cols].fillna(\"Unknown\")\ntest_df[categorical_cols] = test_df[categorical_cols].fillna(\"Unknown\")\n\nnumerical_cols = [\"Academic Pressure\", \"Work Pressure\", \"CGPA\", \"Study Satisfaction\", \"Job Satisfaction\"]\nfor col in numerical_cols:\n    median_value = train_df[col].median()\n    train_df[col].fillna(median_value, inplace=True)\n    test_df[col].fillna(median_value, inplace=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Encoding Ordinal Categorical Variables","metadata":{}},{"cell_type":"code","source":"# Define ordinal encoding for Sleep Duration\nsleep_mapping = {\n    \"Very Short Sleep\": 1,\n    \"Short Sleep\": 2,\n    \"Normal Sleep\": 3,\n    \"Long Sleep\": 4\n}\n\n# Apply encoding to train dataset\ntrain_df[\"Sleep Duration\"] = train_df[\"Sleep Duration\"].map(sleep_mapping)\n\n# Apply encoding to test dataset\ntest_df[\"Sleep Duration\"] = test_df[\"Sleep Duration\"].map(sleep_mapping)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Encoding Binary Categorical Features","metadata":{}},{"cell_type":"code","source":"# Encode binary categorical features\nbinary_features = [\"Have you ever had suicidal thoughts ?\", \"Family History of Mental Illness\"]\nfor col in binary_features:\n    train_df[col] = train_df[col].map({\"Yes\": 1, \"No\": 0})\n    test_df[col] = test_df[col].map({\"Yes\": 1, \"No\": 0})","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## One-Hot Encoding Categorical Variables","metadata":{}},{"cell_type":"code","source":"# One-hot encode categorical variables\ntrain_df = pd.get_dummies(train_df, drop_first=True)\ntest_df = pd.get_dummies(test_df, drop_first=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Ensuring Both Datasets Have the Same Columns","metadata":{}},{"cell_type":"code","source":"# Ensure both datasets have the same columns\nmissing_cols = set(train_df.columns) - set(test_df.columns)\nfor col in missing_cols:\n    test_df[col] = 0\n\ntest_df = test_df[train_df.drop(columns=[\"Depression\"]).columns]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 06. Feature Engineering","metadata":{}},{"cell_type":"code","source":"# Fill missing values only in numeric columns\nnum_cols = [\"CGPA\", \"Financial Stress\"]\n\ntrain_df[num_cols] = train_df[num_cols].apply(lambda x: x.fillna(x.median()))\ntest_df[num_cols] = test_df[num_cols].apply(lambda x: x.fillna(x.median()))\n\n#  Interaction Features\ntrain_df[\"Overall_Stress\"] = train_df[\"Work Pressure\"] * train_df[\"Financial Stress\"]\ntest_df[\"Overall_Stress\"] = test_df[\"Work Pressure\"] * test_df[\"Financial Stress\"]\n\n# Binning Continuous Variables\nbinning = KBinsDiscretizer(n_bins=3, encode=\"ordinal\", strategy=\"quantile\")\n\nfor col in [\"Age\", \"CGPA\", \"Financial Stress\"]:\n    train_df[f\"{col}_Binned\"] = binning.fit_transform(train_df[[col]])\n    test_df[f\"{col}_Binned\"] = binning.transform(test_df[[col]])\n\n\n# Feature Scaling (Only numerical features, not categorical ones)\nscaler = StandardScaler()\nnum_cols = [\"Work Pressure\", \"Financial Stress\", \"Overall_Stress\"]  \ntrain_df[num_cols] = scaler.fit_transform(train_df[num_cols])\ntest_df[num_cols] = scaler.transform(test_df[num_cols])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 07. Model Preparation","metadata":{}},{"cell_type":"markdown","source":"## Splitting features and target","metadata":{}},{"cell_type":"code","source":"# Split features and target\nX = train_df.drop(columns=[\"Depression\"])\ny = train_df[\"Depression\"]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Splitting Training Data for Validation","metadata":{}},{"cell_type":"code","source":"# Split training data for validation\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 08. Training & Evaluating the Model","metadata":{}},{"cell_type":"markdown","source":"## Trainning XGBoost Model","metadata":{}},{"cell_type":"code","source":"# Train XGBoost model\nxgb_model = xgb.XGBClassifier(n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42, eval_metric='logloss')\nxgb_model.fit(X_train, y_train)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Predicting on Validation Set","metadata":{}},{"cell_type":"code","source":"# Predict on validation set\ny_val_pred = xgb_model.predict(X_val)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"##  Computing Accuracy","metadata":{}},{"cell_type":"code","source":"# Assuming y_val contains true labels and y_val_pred contains predicted labels\nreport = classification_report(y_val, y_val_pred, digits=2)\nval_accuracy = accuracy_score(y_val, y_val_pred)\n\nprint(\"Validation Metrics:\")\nprint(report)\nprint(f\"Validation Accuracy: {val_accuracy:.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 09. Making Predictions & Submission","metadata":{}},{"cell_type":"markdown","source":"##  Predicting on Test Set","metadata":{}},{"cell_type":"code","source":"# Predict on test set\ntest_predictions = xgb_model.predict(test_df)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Preparing Submission File","metadata":{}},{"cell_type":"code","source":"# Prepare submission file\nsubmission = pd.DataFrame({\"id\": pd.read_csv(test_path)[\"id\"], \"Depression\": test_predictions})\nsubmission.to_csv(\"submission.csv\", index=False)\nprint(\"Submission file saved as submission.csv\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}
